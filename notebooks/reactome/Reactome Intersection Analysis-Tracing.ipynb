{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intersection Analysis and Tracing\n",
    "Adapted from curli intersection analysis by Sebastian (July 07, 2022)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Definition:\n",
    "Given a list of source nodes and a list of target nodes, find the potential most important nodes from sources to targets. \n",
    "\n",
    "#### Approaches:\n",
    "1. Run personalized pagerank using source nodes. The pagerank value is considered to be the probability that the node is influenced by the source nodes. \n",
    "2. Run personalized reverse pagerank using target nodes. The reverse pagerank value is considered to be the probability that the node influences the target nodes.\n",
    "3. Use a probability formula to get a intersection pagerank that represents the possibility that the node being influenced by the source nodes and also influences the target nodes.\n",
    "\n",
    "<img src=\"img/intersection.png\" width=\"400\" height=\"200\" />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Steps to run Intersection Analysis\n",
    "1. Connect to arango database\n",
    "2. Find input nodes (source nodes and target nodes) in arango database\n",
    "3. Load the whole network graph from arango to memory and create a networkx graph. NetworkX is a python network library.\n",
    "4. Perform intersection analysis\n",
    "    - Run personalized pagerank algorithm using source nodes to get pagerank values for each nodes \n",
    "that the source nodes can reach (forward direction). Those are the nodes influenced by the source nodes\n",
    "    - Run personalized reverse pagerank using target nodes to get the reverce pagerank values for each \n",
    "nodes that can reach the target nodes\n",
    "    - Calculate the intersection pageranks based on source pageranks and target reverse pageranks\n",
    "    - Export the pagerank values into __excel file__\n",
    "5. The user analyzes the pagerank values (sorting, filtering etc), and select the rows that are interesting\n",
    "6. Create intersection traces for selected nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "root = os.getcwd().split('\\\\notebooks\\\\')[0]\n",
    "sys.path.append(os.path.join(root, 'src'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lifelike_gds.arango_network.reactome import *\n",
    "from lifelike_gds.arango_network.radiate_trace import RadiateTrace\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = 'input'\n",
    "output_dir = 'output_intersection'\n",
    "os.makedirs(output_dir, 0o777, True)\n",
    "# gds database name\n",
    "arango_dbname = 'reactome'\n",
    "# gds database version, free text, that can be used to describe the graph\n",
    "db_version = 'reactome-arango-test-1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Connect to arango database.\n",
    "If use BioCyc databases (e.g. EcoCyc, HumanCyc), use Class BioCycDB.  \n",
    "If use Reactome database, use Class ReactomeDB. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set database uri, username and password. \n",
    "# dbname is the arango database name for the running arango instance. The default database name is 'arango'\n",
    "database = ReactomeDB(dbname=arango_dbname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2a. Define functions to get source/target nodes\n",
    "read input file with ids (stId or dbId)\n",
    "read input file with reference ids (gene_id or chebi_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "read csv file to get list of reactome nodes\n",
    "\n",
    "Parameters\n",
    "----------\n",
    "csv_filename:  the input file\n",
    "id_name: the property name in reactome db, e.g. stId, dbId\n",
    "id_column: the column name for the id property\n",
    "\"\"\" \n",
    "def get_nodes_by_identity_from_file(csv_filename, id_name, id_column, sep=','):\n",
    "    df = pd.read_csv(os.path.join(input_dir, csv_filename), sep=sep, dtype='str')\n",
    "    ids = [n for n in df[id_column]]\n",
    "    nodes = database.get_nodes_by_attr(ids, id_name)\n",
    "    print('file_rows:', len(df), ', nodes matched:', len(nodes))\n",
    "    return nodes\n",
    "\n",
    "\n",
    "def get_chemical_nodes_by_chebi(csv_filename, chebi_id_column, sep=','):\n",
    "    df = pd.read_csv(os.path.join(input_dir, csv_filename), sep=sep, dtype='str')\n",
    "    ids = [n for n in df[chebi_id_column]]\n",
    "    nodes = database.get_entity_nodes_by_chebi_ids(ids)\n",
    "    print('file_rows:', len(df), ', nodes matched:', len(nodes))\n",
    "    return nodes\n",
    "\n",
    "def get_protein_nodes_by_gene_id(csv_filename, gene_id_column, sep=','):\n",
    "    df = pd.read_csv(os.path.join(input_dir, csv_filename), sep=sep, dtype='str')\n",
    "    ids = [n for n in df[gene_id_column]]\n",
    "    nodes = database.get_entity_nodes_by_gene_ids(ids)\n",
    "    print('file_rows:', len(df), ', nodes matched:', len(nodes))\n",
    "    return nodes\n",
    "\n",
    "def get_reference_nodes_by_chebi(csv_filename, chebi_id_column, sep=','):\n",
    "    df = pd.read_csv(os.path.join(input_dir, csv_filename), sep=sep, dtype='str')\n",
    "    ids = [n for n in df[chebi_id_column]]\n",
    "    nodes = database.get_reference_nodes_by_chebi_ids(ids)\n",
    "    print('file_rows:', len(df), ', nodes matched:', len(nodes))\n",
    "    return nodes\n",
    "\n",
    "def get_reference_nodes_by_gene_id(csv_filename, gene_id_column, sep=','):\n",
    "    df = pd.read_csv(os.path.join(input_dir, csv_filename), sep=sep, dtype='str')\n",
    "    ids = [n for n in df[gene_id_column]]\n",
    "    nodes = database.get_reference_nodes_by_gene_ids(ids)\n",
    "    print('file_rows:', len(df), ', nodes matched:', len(nodes))\n",
    "    return nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2b. Find input nodes (source and target nodes) in arango database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read updown genes as sources, and metabolites as targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:92 gene_ids, matched to 119 nodes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file_rows: 92 , nodes matched: 119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:23 chebi_ids, matched to 13 nodes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file_rows: 23 , nodes matched: 13\n"
     ]
    }
   ],
   "source": [
    "# sources: updown genes\n",
    "updown_genes_file = 'updown.entrez'\n",
    "#df1 = pd.read_csv(os.path.join(input_dir, updown_genes_file))\n",
    "#updown_genes = [n for n in df1['gene_id']]\n",
    "updown_nodes = get_protein_nodes_by_gene_id(csv_filename=updown_genes_file, gene_id_column='gene_id')\n",
    "#print(f\"updown genes: {len(updown_genes)}, nodes: {len(updown_nodes)}\")\n",
    "\n",
    "\n",
    "# targets: metabolites\n",
    "metabs_file = 'metabolite.txt'\n",
    "#df3 = pd.read_csv(os.path.join(input_dir, metabs_file))\n",
    "#metabs = [n for n in df3['chebi']]\n",
    "\n",
    "######to be changed to reactome mapping function (get from radiate script)\n",
    "metabs_nodes = get_chemical_nodes_by_chebi(csv_filename=metabs_file, chebi_id_column='chebi')\n",
    "#print(f\"metabolites: {len(metabs)}, nodes: {len(metabs_nodes)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load the whole network graph from arango to memory and create a networkx graph\n",
    "\n",
    "Create a RadiateTrace instance.  \n",
    "RadiateTrace is a subclass of TraceGraphNx.  TraceGraphNx has a property __graph__, that is a networkx graph. After the graph is created by using data from arango graph database, all the algorithms and traces can be run using the python networkx library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:load reactome graph\n",
      "INFO:root:MultiDirectedGraph with 71225 nodes and 112575 edges\n"
     ]
    }
   ],
   "source": [
    "tracegraph = RadiateTrace(Reactome(database))\n",
    "# set up output directory where the excel and graph files will write to\n",
    "tracegraph.datadir = output_dir\n",
    "# initiate tracegraph by loading graph data from arango\n",
    "tracegraph.init_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Perform intersection analysis\n",
    "Run intersection pagerank analysis and export values into excel file.\n",
    "\n",
    "The pagerank analysis is performed using networkx graph that contains a set of nodes and set of edges. \n",
    "\n",
    "#### Set node sets for sources and targets.  \n",
    "A node set is a list of node ids with a name and description.\n",
    "\n",
    "We set two source node sets and one target node set.  Then we will perform intersection analysis from each source node set to the target node set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set source and target node sets\n",
    "SOURCE_SET = 'updown_genes'\n",
    "TARGET_SET = 'metabolites'\n",
    "\n",
    "tracegraph.set_node_set_from_arango_nodes(updown_nodes, SOURCE_SET, 'updown_genes')\n",
    "tracegraph.set_node_set_from_arango_nodes(metabs_nodes, TARGET_SET, 'metabolites')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Call export_intersection_pageranks\n",
    "The method export_intersection_pageranks() performs the following steps\n",
    "1. Run personalized pagerank using source nodes\n",
    "2. Run personalized reverse pagerank using target nodes\n",
    "3. Calculate intersection pagerank based on source pagerank and target reverse pagerank\n",
    "4. Write values into excel file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:set pagerank and num reach for updown_genes\n",
      "INFO:root:set pagerank and num reach for metabolites\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "export intersection pagerank to file  output_intersection/Intersection_analysis_for_updown_genes_and_metabolites.xlsx\n"
     ]
    }
   ],
   "source": [
    "# keep a clean copy of graph\n",
    "tracegraph.graph = tracegraph.orig_graph.copy()\n",
    "\n",
    "filename = f\"Intersection_analysis_for_{SOURCE_SET}_and_{TARGET_SET}.xlsx\"\n",
    "tracegraph.export_intersection_pageranks(filename, SOURCE_SET, TARGET_SET, num_nodes=3000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Analyze the pagerank output file (excel), and select interesting rows for further analysis\n",
    "\n",
    "#### Suggestion:   \n",
    "Add a column 'select' for selecting top pagerank nodes, and set any selected rows to 1, then save the file "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Create intersection traces for the selected rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read manually selected top ranked nodes from the previous generated pagerank excel file\n",
    "We will read the column 'select' to get the selected rows (for intersection pagerank selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "            stId  select\n6    R-ALL-29654     1.0\n7  R-HSA-1614665     1.0\n8    R-HSA-70975     1.0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>stId</th>\n      <th>select</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>6</th>\n      <td>R-ALL-29654</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>R-HSA-1614665</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>R-HSA-70975</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intersect_pagerank_select_file = f\"Intersection_analysis_for_{SOURCE_SET}_and_{TARGET_SET}_select.xlsx\"\n",
    "\n",
    "#adapted by Sebastian to use stId-->double-check with Robin\n",
    "df = pd.read_excel(os.path.join(input_dir, intersect_pagerank_select_file), usecols=['stId', 'select'])\n",
    "df = df[df['select']==1]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['R-ALL-29654', 'R-HSA-1614665', 'R-HSA-70975']\n",
      "No. of selected nodes:  3\n"
     ]
    }
   ],
   "source": [
    "#adapted by Sebastian to use stId-->double-check with Robin\n",
    "#also double-check if get_nodes_by_attr function is ok to use here\n",
    "selected_stIds = [id for id in df['stId']]\n",
    "print(selected_stIds)\n",
    "selected_nodes = database.get_nodes_by_attr(selected_stIds, 'stId')\n",
    "print('No. of selected nodes: ', len(selected_nodes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run pageranks again using a clean copy of the original graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracegraph.graph = tracegraph.orig_graph.copy()\n",
    "\n",
    "pr = 'pagerank'\n",
    "rev_pr = 'rev_pagerank'\n",
    "tracegraph.set_pagerank(SOURCE_SET, pagerank_prop=pr)\n",
    "tracegraph.set_pagerank(TARGET_SET, pagerank_prop=rev_pr, reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add traces from sources to the intersection node, and intersection node to targets\n",
    "We will add traces from source nodes to each selected intersection nodes, and traces from each selected intersection nodes to targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Adding trace network updown_genes to CIT [mitochondrial matrix] #1\n",
      "INFO:root:Adding trace network updown_genes to Acetyl-CoA + H2O + Oxaloacetate => Citrate + CoA #2\n",
      "INFO:root:Adding trace network updown_genes to SQR oxidizes sulfide to bound persulfide #3\n",
      "INFO:root:Adding trace network from CIT [mitochondrial matrix] #1 to metabolites\n",
      "INFO:root:Adding trace network from Acetyl-CoA + H2O + Oxaloacetate => Citrate + CoA #2 to metabolites\n",
      "INFO:root:Adding trace network from SQR oxidizes sulfide to bound persulfide #3 to metabolites\n"
     ]
    }
   ],
   "source": [
    "# write traces in one file\n",
    "tracegraph.add_traces_from_sources_to_each_selected_nodes(selected_nodes, SOURCE_SET, weighted_prop=pr)\n",
    "tracegraph.add_traces_from_each_selected_nodes_to_targets(selected_nodes, TARGET_SET, weighted_prop=rev_pr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:clean graph: number of graph nodes decreased from 71225 to 1081\n",
      "INFO:root:writing output_intersection/Intersection_traces_from_updown_genes_to_metabolites\n"
     ]
    }
   ],
   "source": [
    "tracegraph.write_to_sankey_file(f\"Intersection_traces_from_{SOURCE_SET}_to_{TARGET_SET}.graph\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
