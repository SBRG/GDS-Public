{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intersection Analysis and Tracing\n",
    "Adapted from curli intersection analysis by Sebastian (July 07, 2022)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Definition:\n",
    "Given a list of source nodes and a list of target nodes, find the potential most important nodes from sources to targets. \n",
    "\n",
    "#### Approaches:\n",
    "1. Run personalized pagerank using source nodes. The pagerank value is considered to be the probability that the node is influenced by the source nodes. \n",
    "2. Run personalized reverse pagerank using target nodes. The reverse pagerank value is considered to be the probability that the node influences the target nodes.\n",
    "3. Use a probability formula to get a intersection pagerank that represents the possibility that the node being influenced by the source nodes and also influences the target nodes.\n",
    "\n",
    "<img src=\"img/intersection.png\" width=\"400\" height=\"200\" />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Steps to run Intersection Analysis\n",
    "1. Connect to arango database\n",
    "2. Find input nodes (source nodes and target nodes) in arango database\n",
    "3. Load the whole network graph from arango to memory and create a networkx graph. NetworkX is a python network library.\n",
    "4. Perform intersection analysis\n",
    "    - Run personalized pagerank algorithm using source nodes to get pagerank values for each nodes \n",
    "that the source nodes can reach (forward direction). Those are the nodes influenced by the source nodes\n",
    "    - Run personalized reverse pagerank using target nodes to get the reverce pagerank values for each \n",
    "nodes that can reach the target nodes\n",
    "    - Calculate the intersection pageranks based on source pageranks and target reverse pageranks\n",
    "    - Export the pagerank values into __excel file__\n",
    "5. The user analyzes the pagerank values (sorting, filtering etc), and select the rows that are interesting\n",
    "6. Create intersection traces for selected nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lifelike_gds.arango_network.reactome import *\n",
    "from lifelike_gds.arango_network.radiate_trace import RadiateTrace\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = 'input'\n",
    "output_dir = 'output_intersection'\n",
    "os.makedirs(output_dir, 0o777, True)\n",
    "# gds database name\n",
    "arango_dbname = 'reactome'\n",
    "# gds database version, free text, that can be used to describe the graph\n",
    "db_version = 'reactome-arango-test-1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Connect to arango database.\n",
    "If use BioCyc databases (e.g. EcoCyc, HumanCyc), use Class BioCycDB.  \n",
    "If use Reactome database, use Class ReactomeDB. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set database uri, username and password. \n",
    "# dbname is the arango database name for the running arango instance. The default database name is 'arango'\n",
    "database = ReactomeDB(dbname=arango_dbname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2a. Define functions to get source/target nodes\n",
    "read input file with ids (stId or dbId)\n",
    "read input file with reference ids (gene_id or chebi_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "read csv file to get list of reactome nodes\n",
    "\n",
    "Parameters\n",
    "----------\n",
    "csv_filename:  the input file\n",
    "id_name: the property name in reactome db, e.g. stId, dbId\n",
    "id_column: the column name for the id property\n",
    "\"\"\" \n",
    "def get_nodes_by_identity_from_file(csv_filename, id_name, id_column, sep=','):\n",
    "    df = pd.read_csv(os.path.join(input_dir, csv_filename), sep=sep, dtype='str')\n",
    "    ids = [n for n in df[id_column]]\n",
    "    nodes = database.get_nodes_by_attr(ids, id_name)\n",
    "    print('file_rows:', len(df), ', nodes matched:', len(nodes))\n",
    "    return nodes\n",
    "\n",
    "\n",
    "def get_chemical_nodes_by_chebi(csv_filename, chebi_id_column, sep=','):\n",
    "    df = pd.read_csv(os.path.join(input_dir, csv_filename), sep=sep, dtype='str')\n",
    "    ids = [n for n in df[chebi_id_column]]\n",
    "    nodes = database.get_entity_nodes_by_chebi_ids(ids)\n",
    "    print('file_rows:', len(df), ', nodes matched:', len(nodes))\n",
    "    return nodes\n",
    "\n",
    "def get_protein_nodes_by_gene_id(csv_filename, gene_id_column, sep=','):\n",
    "    df = pd.read_csv(os.path.join(input_dir, csv_filename), sep=sep, dtype='str')\n",
    "    ids = [n for n in df[gene_id_column]]\n",
    "    nodes = database.get_entity_nodes_by_gene_ids(ids)\n",
    "    print('file_rows:', len(df), ', nodes matched:', len(nodes))\n",
    "    return nodes\n",
    "\n",
    "def get_reference_nodes_by_chebi(csv_filename, chebi_id_column, sep=','):\n",
    "    df = pd.read_csv(os.path.join(input_dir, csv_filename), sep=sep, dtype='str')\n",
    "    ids = [n for n in df[chebi_id_column]]\n",
    "    nodes = database.get_reference_nodes_by_chebi_ids(ids)\n",
    "    print('file_rows:', len(df), ', nodes matched:', len(nodes))\n",
    "    return nodes\n",
    "\n",
    "def get_reference_nodes_by_gene_id(csv_filename, gene_id_column, sep=','):\n",
    "    df = pd.read_csv(os.path.join(input_dir, csv_filename), sep=sep, dtype='str')\n",
    "    ids = [n for n in df[gene_id_column]]\n",
    "    nodes = database.get_reference_nodes_by_gene_ids(ids)\n",
    "    print('file_rows:', len(df), ', nodes matched:', len(nodes))\n",
    "    return nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2b. Find input nodes (source and target nodes) in arango database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read updown genes as sources, and metabolites as targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: 92 gene_ids, matched to 119 nodes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file_rows: 92 , nodes matched: 119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: 23 chebi_ids, matched to 13 nodes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file_rows: 23 , nodes matched: 13\n"
     ]
    }
   ],
   "source": [
    "# sources: updown genes\n",
    "updown_genes_file = 'updown.entrez'\n",
    "#df1 = pd.read_csv(os.path.join(input_dir, updown_genes_file))\n",
    "#updown_genes = [n for n in df1['gene_id']]\n",
    "updown_nodes = get_protein_nodes_by_gene_id(csv_filename=updown_genes_file, gene_id_column='gene_id')\n",
    "#print(f\"updown genes: {len(updown_genes)}, nodes: {len(updown_nodes)}\")\n",
    "\n",
    "\n",
    "# targets: metabolites\n",
    "metabs_file = 'metabolite.txt'\n",
    "#df3 = pd.read_csv(os.path.join(input_dir, metabs_file))\n",
    "#metabs = [n for n in df3['chebi']]\n",
    "\n",
    "######to be changed to reactome mapping function (get from radiate script)\n",
    "metabs_nodes = get_chemical_nodes_by_chebi(csv_filename=metabs_file, chebi_id_column='chebi')\n",
    "#print(f\"metabolites: {len(metabs)}, nodes: {len(metabs_nodes)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load the whole network graph from arango to memory and create a networkx graph\n",
    "\n",
    "Create a RadiateTrace instance.  \n",
    "RadiateTrace is a subclass of TraceGraphNx.  TraceGraphNx has a property __graph__, that is a networkx graph. After the graph is created by using data from arango graph database, all the algorithms and traces can be run using the python networkx library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: load reactome graph\n",
      "INFO: MultiDirectedGraph with 71225 nodes and 112575 edges\n"
     ]
    }
   ],
   "source": [
    "tracegraph = RadiateTrace(Reactome(database))\n",
    "# set up output directory where the excel and graph files will write to\n",
    "tracegraph.datadir = output_dir\n",
    "# initiate tracegraph by loading graph data from arango\n",
    "tracegraph.init_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Perform intersection analysis\n",
    "Run intersection pagerank analysis and export values into excel file.\n",
    "\n",
    "The pagerank analysis is performed using networkx graph that contains a set of nodes and set of edges. \n",
    "\n",
    "#### Set node sets for sources and targets.  \n",
    "A node set is a list of node ids with a name and description.\n",
    "\n",
    "We set two source node sets and one target node set.  Then we will perform intersection analysis from each source node set to the target node set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set source and target node sets\n",
    "SOURCE_SET = 'updown_genes'\n",
    "TARGET_SET = 'metabolites'\n",
    "\n",
    "tracegraph.set_node_set_from_arango_nodes(updown_nodes, SOURCE_SET, 'updown_genes')\n",
    "tracegraph.set_node_set_from_arango_nodes(metabs_nodes, TARGET_SET, 'metabolites')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Call export_intersection_pageranks\n",
    "The method export_intersection_pageranks() performs the following steps\n",
    "1. Run personalized pagerank using source nodes\n",
    "2. Run personalized reverse pagerank using target nodes\n",
    "3. Calculate intersection pagerank based on source pagerank and target reverse pagerank\n",
    "4. Write values into excel file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: set pagerank and num reach for updown_genes\n",
      "INFO: set pagerank and num reach for metabolites\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "export intersection pagerank to file  output_intersection/Intersection_analysis_for_updown_genes_and_metabolites.xlsx\n"
     ]
    }
   ],
   "source": [
    "# keep a clean copy of graph\n",
    "tracegraph.graph = tracegraph.orig_graph.copy()\n",
    "\n",
    "filename = f\"Intersection_analysis_for_{SOURCE_SET}_and_{TARGET_SET}.xlsx\"\n",
    "tracegraph.export_intersection_pageranks(filename, SOURCE_SET, TARGET_SET, num_nodes=3000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Analyze the pagerank output file (excel), and select interesting rows for further analysis\n",
    "\n",
    "#### Suggestion:   \n",
    "Add a column 'select' for selecting top pagerank nodes, and set any selected rows to 1, then save the file "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Create intersection traces for the selected rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read manually selected top ranked nodes from the previous generated pagerank excel file\n",
    "We will read the column 'select' to get the selected rows (for intersection pagerank selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'input/Intersection_analysis_for_updown_genes_and_metabolites_select.xlsx'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m intersect_pagerank_select_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIntersection_analysis_for_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mSOURCE_SET\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_and_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mTARGET_SET\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_select.xlsx\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#adapted by Sebastian to use stId-->double-check with Robin\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_excel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mintersect_pagerank_select_file\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43musecols\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mstId\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mselect\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m df \u001b[38;5;241m=\u001b[39m df[df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mselect\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m      6\u001b[0m df\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/GDS-Public-uKBS7cUg/lib/python3.9/site-packages/pandas/util/_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    306\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    307\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[1;32m    308\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    309\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[1;32m    310\u001b[0m     )\n\u001b[0;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/GDS-Public-uKBS7cUg/lib/python3.9/site-packages/pandas/io/excel/_base.py:364\u001b[0m, in \u001b[0;36mread_excel\u001b[0;34m(io, sheet_name, header, names, index_col, usecols, squeeze, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, thousands, comment, skipfooter, convert_float, mangle_dupe_cols, storage_options)\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(io, ExcelFile):\n\u001b[1;32m    363\u001b[0m     should_close \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 364\u001b[0m     io \u001b[38;5;241m=\u001b[39m \u001b[43mExcelFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mio\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    365\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m engine \u001b[38;5;129;01mand\u001b[39;00m engine \u001b[38;5;241m!=\u001b[39m io\u001b[38;5;241m.\u001b[39mengine:\n\u001b[1;32m    366\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    367\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEngine should not be specified when passing \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    368\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124man ExcelFile - ExcelFile already has the engine set\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    369\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/GDS-Public-uKBS7cUg/lib/python3.9/site-packages/pandas/io/excel/_base.py:1191\u001b[0m, in \u001b[0;36mExcelFile.__init__\u001b[0;34m(self, path_or_buffer, engine, storage_options)\u001b[0m\n\u001b[1;32m   1189\u001b[0m     ext \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxls\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1191\u001b[0m     ext \u001b[38;5;241m=\u001b[39m \u001b[43minspect_excel_format\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1192\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontent_or_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\n\u001b[1;32m   1193\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1194\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ext \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1195\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1196\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExcel file format cannot be determined, you must specify \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1197\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124man engine manually.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1198\u001b[0m         )\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/GDS-Public-uKBS7cUg/lib/python3.9/site-packages/pandas/io/excel/_base.py:1070\u001b[0m, in \u001b[0;36minspect_excel_format\u001b[0;34m(content_or_path, storage_options)\u001b[0m\n\u001b[1;32m   1067\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(content_or_path, \u001b[38;5;28mbytes\u001b[39m):\n\u001b[1;32m   1068\u001b[0m     content_or_path \u001b[38;5;241m=\u001b[39m BytesIO(content_or_path)\n\u001b[0;32m-> 1070\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1071\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcontent_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[1;32m   1072\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handle:\n\u001b[1;32m   1073\u001b[0m     stream \u001b[38;5;241m=\u001b[39m handle\u001b[38;5;241m.\u001b[39mhandle\n\u001b[1;32m   1074\u001b[0m     stream\u001b[38;5;241m.\u001b[39mseek(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/GDS-Public-uKBS7cUg/lib/python3.9/site-packages/pandas/io/common.py:711\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    702\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[1;32m    703\u001b[0m             handle,\n\u001b[1;32m    704\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    707\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    708\u001b[0m         )\n\u001b[1;32m    709\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    710\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m--> 711\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    712\u001b[0m     handles\u001b[38;5;241m.\u001b[39mappend(handle)\n\u001b[1;32m    714\u001b[0m \u001b[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'input/Intersection_analysis_for_updown_genes_and_metabolites_select.xlsx'"
     ]
    }
   ],
   "source": [
    "intersect_pagerank_select_file = f\"Intersection_analysis_for_{SOURCE_SET}_and_{TARGET_SET}_select.xlsx\"\n",
    "\n",
    "#adapted by Sebastian to use stId-->double-check with Robin\n",
    "df = pd.read_excel(os.path.join(input_dir, intersect_pagerank_select_file), usecols=['stId', 'select'])\n",
    "df = df[df['select']==1]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adapted by Sebastian to use stId-->double-check with Robin\n",
    "#also double-check if get_nodes_by_attr function is ok to use here\n",
    "selected_stIds = [id for id in df['stId']]\n",
    "print(selected_stIds)\n",
    "selected_nodes = database.get_nodes_by_attr(selected_stIds, 'stId')\n",
    "print('No. of selected nodes: ', len(selected_nodes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run pageranks again using a clean copy of the original graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracegraph.graph = tracegraph.orig_graph.copy()\n",
    "\n",
    "pr = 'pagerank'\n",
    "rev_pr = 'rev_pagerank'\n",
    "tracegraph.set_pagerank(SOURCE_SET, pagerank_prop=pr)\n",
    "tracegraph.set_pagerank(TARGET_SET, pagerank_prop=rev_pr, reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add traces from sources to the intersection node, and intersection node to targets\n",
    "We will add traces from source nodes to each selected intersection nodes, and traces from each selected intersection nodes to targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write traces in one file\n",
    "tracegraph.add_traces_from_sources_to_each_selected_nodes(selected_nodes, SOURCE_SET, weighted_prop=pr)\n",
    "tracegraph.add_traces_from_each_selected_nodes_to_targets(selected_nodes, TARGET_SET, weighted_prop=rev_pr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "tracegraph.write_to_sankey_file(f\"Intersection_traces_from_{SOURCE_SET}_to_{TARGET_SET}.graph\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
